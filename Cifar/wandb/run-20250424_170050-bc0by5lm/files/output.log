


================================================================================

Iteration start: 1/1

==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
model ResNet50
Growth mode: global_gradients not supported!
Supported modes are: ['random', 'momentum', 'momentum_neuron', 'gradient']
ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layer1): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): Bottleneck(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer2): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (3): Bottleneck(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer3): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (3): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (4): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (5): Bottleneck(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (layer4): Sequential(
    (0): Bottleneck(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
    (2): Bottleneck(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shortcut): Sequential()
    )
  )
  (classifier): Linear(in_features=2048, out_features=100, bias=False)
)
add module
Removing biases...
Removed 53 layers.
Removing 2D batch norms...
Removing bn1 of size torch.Size([64]) = 64 parameters.
Removing layer1.0.bn1 of size torch.Size([64]) = 64 parameters.
Removing layer1.0.bn2 of size torch.Size([64]) = 64 parameters.
Removing layer1.0.bn3 of size torch.Size([256]) = 256 parameters.
Removing layer1.0.shortcut.1 of size torch.Size([256]) = 256 parameters.
Removing layer1.1.bn1 of size torch.Size([64]) = 64 parameters.
Removing layer1.1.bn2 of size torch.Size([64]) = 64 parameters.
Removing layer1.1.bn3 of size torch.Size([256]) = 256 parameters.
Removing layer1.2.bn1 of size torch.Size([64]) = 64 parameters.
Removing layer1.2.bn2 of size torch.Size([64]) = 64 parameters.
Removing layer1.2.bn3 of size torch.Size([256]) = 256 parameters.
Removing layer2.0.bn1 of size torch.Size([128]) = 128 parameters.
Removing layer2.0.bn2 of size torch.Size([128]) = 128 parameters.
Removing layer2.0.bn3 of size torch.Size([512]) = 512 parameters.
Removing layer2.0.shortcut.1 of size torch.Size([512]) = 512 parameters.
Removing layer2.1.bn1 of size torch.Size([128]) = 128 parameters.
Removing layer2.1.bn2 of size torch.Size([128]) = 128 parameters.
Removing layer2.1.bn3 of size torch.Size([512]) = 512 parameters.
Removing layer2.2.bn1 of size torch.Size([128]) = 128 parameters.
Removing layer2.2.bn2 of size torch.Size([128]) = 128 parameters.
Removing layer2.2.bn3 of size torch.Size([512]) = 512 parameters.
Removing layer2.3.bn1 of size torch.Size([128]) = 128 parameters.
Removing layer2.3.bn2 of size torch.Size([128]) = 128 parameters.
Removing layer2.3.bn3 of size torch.Size([512]) = 512 parameters.
Removing layer3.0.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.0.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.0.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.0.shortcut.1 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.1.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.1.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.1.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.2.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.2.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.2.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.3.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.3.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.3.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.4.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.4.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.4.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer3.5.bn1 of size torch.Size([256]) = 256 parameters.
Removing layer3.5.bn2 of size torch.Size([256]) = 256 parameters.
Removing layer3.5.bn3 of size torch.Size([1024]) = 1024 parameters.
Removing layer4.0.bn1 of size torch.Size([512]) = 512 parameters.
Removing layer4.0.bn2 of size torch.Size([512]) = 512 parameters.
Removing layer4.0.bn3 of size torch.Size([2048]) = 2048 parameters.
Removing layer4.0.shortcut.1 of size torch.Size([2048]) = 2048 parameters.
Removing layer4.1.bn1 of size torch.Size([512]) = 512 parameters.
Removing layer4.1.bn2 of size torch.Size([512]) = 512 parameters.
Removing layer4.1.bn3 of size torch.Size([2048]) = 2048 parameters.
Removing layer4.2.bn1 of size torch.Size([512]) = 512 parameters.
Removing layer4.2.bn2 of size torch.Size([512]) = 512 parameters.
Removing layer4.2.bn3 of size torch.Size([2048]) = 2048 parameters.
Removing 1D batch norms...
baseline fitler num 7552
initialize by fixed_ERK
Sparsity of var:conv1.weight had to be set to 0.
Sparsity of var:layer1.0.conv1.weight had to be set to 0.
layer: conv1.weight, shape: torch.Size([64, 3, 3, 3]), density: 1.0
layer: layer1.0.conv1.weight, shape: torch.Size([64, 64, 1, 1]), density: 1.0
layer: layer1.0.conv2.weight, shape: torch.Size([64, 64, 3, 3]), density: 0.16747319723795276
layer: layer1.0.conv3.weight, shape: torch.Size([256, 64, 1, 1]), density: 0.9054800850663938
layer: layer1.0.shortcut.0.weight, shape: torch.Size([256, 64, 1, 1]), density: 0.9054800850663938
layer: layer1.1.conv1.weight, shape: torch.Size([64, 256, 1, 1]), density: 0.9054800850663938
layer: layer1.1.conv2.weight, shape: torch.Size([64, 64, 3, 3]), density: 0.16747319723795276
layer: layer1.1.conv3.weight, shape: torch.Size([256, 64, 1, 1]), density: 0.9054800850663938
layer: layer1.2.conv1.weight, shape: torch.Size([64, 256, 1, 1]), density: 0.9054800850663938
layer: layer1.2.conv2.weight, shape: torch.Size([64, 64, 3, 3]), density: 0.16747319723795276
layer: layer1.2.conv3.weight, shape: torch.Size([256, 64, 1, 1]), density: 0.9054800850663938
layer: layer2.0.conv1.weight, shape: torch.Size([128, 256, 1, 1]), density: 0.5427256410491118
layer: layer2.0.conv2.weight, shape: torch.Size([128, 128, 3, 3]), density: 0.08186189864989481
layer: layer2.0.conv3.weight, shape: torch.Size([512, 128, 1, 1]), density: 0.4513340175563857
layer: layer2.0.shortcut.0.weight, shape: torch.Size([512, 256, 1, 1]), density: 0.2706598080361503
layer: layer2.1.conv1.weight, shape: torch.Size([128, 512, 1, 1]), density: 0.4513340175563857
layer: layer2.1.conv2.weight, shape: torch.Size([128, 128, 3, 3]), density: 0.08186189864989481
layer: layer2.1.conv3.weight, shape: torch.Size([512, 128, 1, 1]), density: 0.4513340175563857
layer: layer2.2.conv1.weight, shape: torch.Size([128, 512, 1, 1]), density: 0.4513340175563857
layer: layer2.2.conv2.weight, shape: torch.Size([128, 128, 3, 3]), density: 0.08186189864989481
layer: layer2.2.conv3.weight, shape: torch.Size([512, 128, 1, 1]), density: 0.4513340175563857
layer: layer2.3.conv1.weight, shape: torch.Size([128, 512, 1, 1]), density: 0.4513340175563857
layer: layer2.3.conv2.weight, shape: torch.Size([128, 128, 3, 3]), density: 0.08186189864989481
layer: layer2.3.conv3.weight, shape: torch.Size([512, 128, 1, 1]), density: 0.4513340175563857
layer: layer3.0.conv1.weight, shape: torch.Size([256, 512, 1, 1]), density: 0.2706598080361503
layer: layer3.0.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.0.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer3.0.shortcut.0.weight, shape: torch.Size([1024, 512, 1, 1]), density: 0.13515415089597377
layer: layer3.1.conv1.weight, shape: torch.Size([256, 1024, 1, 1]), density: 0.22531550253399008
layer: layer3.1.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.1.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer3.2.conv1.weight, shape: torch.Size([256, 1024, 1, 1]), density: 0.22531550253399008
layer: layer3.2.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.2.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer3.3.conv1.weight, shape: torch.Size([256, 1024, 1, 1]), density: 0.22531550253399008
layer: layer3.3.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.3.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer3.4.conv1.weight, shape: torch.Size([256, 1024, 1, 1]), density: 0.22531550253399008
layer: layer3.4.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.4.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer3.5.conv1.weight, shape: torch.Size([256, 1024, 1, 1]), density: 0.22531550253399008
layer: layer3.5.conv2.weight, shape: torch.Size([256, 256, 3, 3]), density: 0.04046227433267702
layer: layer3.5.conv3.weight, shape: torch.Size([1024, 256, 1, 1]), density: 0.22531550253399008
layer: layer4.0.conv1.weight, shape: torch.Size([512, 1024, 1, 1]), density: 0.13515415089597377
layer: layer4.0.conv2.weight, shape: torch.Size([512, 512, 3, 3]), density: 0.02011396841827091
layer: layer4.0.conv3.weight, shape: torch.Size([2048, 512, 1, 1]), density: 0.11256987470594433
layer: layer4.0.shortcut.0.weight, shape: torch.Size([2048, 1024, 1, 1]), density: 0.06753313716746152
layer: layer4.1.conv1.weight, shape: torch.Size([512, 2048, 1, 1]), density: 0.11256987470594433
layer: layer4.1.conv2.weight, shape: torch.Size([512, 512, 3, 3]), density: 0.02011396841827091
layer: layer4.1.conv3.weight, shape: torch.Size([2048, 512, 1, 1]), density: 0.11256987470594433
layer: layer4.2.conv1.weight, shape: torch.Size([512, 2048, 1, 1]), density: 0.11256987470594433
layer: layer4.2.conv2.weight, shape: torch.Size([512, 512, 3, 3]), density: 0.02011396841827091
layer: layer4.2.conv3.weight, shape: torch.Size([2048, 512, 1, 1]), density: 0.11256987470594433
layer: classifier.weight, shape: torch.Size([100, 2048]), density: 0.48322266403046304
Overall sparsity 0.10000000000000005
conv1.weight 1728
layer1.0.conv1.weight 4096
layer1.0.conv2.weight 36864
layer1.0.conv3.weight 16384
layer1.0.shortcut.0.weight 16384
layer1.1.conv1.weight 16384
layer1.1.conv2.weight 36864
layer1.1.conv3.weight 16384
layer1.2.conv1.weight 16384
layer1.2.conv2.weight 36864
layer1.2.conv3.weight 16384
layer2.0.conv1.weight 32768
layer2.0.conv2.weight 147456
layer2.0.conv3.weight 65536
layer2.0.shortcut.0.weight 131072
layer2.1.conv1.weight 65536
layer2.1.conv2.weight 147456
layer2.1.conv3.weight 65536
layer2.2.conv1.weight 65536
layer2.2.conv2.weight 147456
layer2.2.conv3.weight 65536
layer2.3.conv1.weight 65536
layer2.3.conv2.weight 147456
layer2.3.conv3.weight 65536
layer3.0.conv1.weight 131072
layer3.0.conv2.weight 589824
layer3.0.conv3.weight 262144
layer3.0.shortcut.0.weight 524288
layer3.1.conv1.weight 262144
layer3.1.conv2.weight 589824
layer3.1.conv3.weight 262144
layer3.2.conv1.weight 262144
layer3.2.conv2.weight 589824
layer3.2.conv3.weight 262144
layer3.3.conv1.weight 262144
layer3.3.conv2.weight 589824
layer3.3.conv3.weight 262144
layer3.4.conv1.weight 262144
layer3.4.conv2.weight 589824
layer3.4.conv3.weight 262144
layer3.5.conv1.weight 262144
layer3.5.conv2.weight 589824
layer3.5.conv3.weight 262144
layer4.0.conv1.weight 524288
layer4.0.conv2.weight 2359296
layer4.0.conv3.weight 1048576
layer4.0.shortcut.0.weight 2097152
layer4.1.conv1.weight 1048576
layer4.1.conv2.weight 2359296
layer4.1.conv3.weight 1048576
layer4.2.conv1.weight 1048576
layer4.2.conv2.weight 2359296
layer4.2.conv3.weight 1048576
classifier.weight 204800
Total Model parameters after init: 2367257 23652032
Total parameters under sparsity level of 0.1: 0.10008683397688621
save_dir ./Chase_models/saved_models/test/density_0.1/stop_gmp_epochs_130/epoch_160/layer_interval_1000/start_layer_rate_0.5
=====================================
begin pre training
Train Epoch: 0 [0/50000 (0%)]	Loss: 4.644441 Accuracy: 0/100 (0.000%
Train Epoch: 0 [10000/50000 (20%)]	Loss: 4.590605 Accuracy: 119/10100 (1.178%
Train Epoch: 0 [20000/50000 (40%)]	Loss: 4.317990 Accuracy: 363/20100 (1.806%
Train Epoch: 0 [30000/50000 (60%)]	Loss: 4.173014 Accuracy: 802/30100 (2.664%
Train Epoch: 0 [40000/50000 (80%)]	Loss: 4.028849 Accuracy: 1416/40100 (3.531%
current layer rate 0.011449931725079632
===========del layer===============
===========del layer with layer-wise HE===============
Traceback (most recent call last):
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/main_dst.py", line 474, in <module>
    main()
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/main_dst.py", line 404, in main
    train(args, model, device, train_loader, epoch,mask)
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/main_dst.py", line 143, in train
    if mask is not None: mask.step()
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/sparselearning/core_dst.py", line 931, in step
    self.del_layer()
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/sparselearning/core_dst.py", line 727, in del_layer
    self.track_hyperspherical_energy()
  File "/home/rpgsbs/r01al21/PycharmProjects/pythonProject/he_dst/Cifar/sparselearning/core_dst.py", line 711, in track_hyperspherical_energy
    metrics[f"layer/{layer_name}/within_layer_variance"] = layer_variances[layer_name]
KeyError: 'layer1.0.conv1'
